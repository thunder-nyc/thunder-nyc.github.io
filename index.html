<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Thunder : C++ 11 Tensor Library">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Thunder</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/thunder-nyc">View on GitHub</a>

          <h1 id="project_title">Thunder</h1>
          <h2 id="project_tagline">C++ 11 Tensor Library</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p>Thunder is a <a href="http://en.wikipedia.org/wiki/C%2B%2B11">C++11</a> library to provide device-transparent Tensor mathematical operations. We are currently working on a first proof-of-idea version of the library, focusing on applications in <a href="http://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> using high-level parallelization and numerical optimization with GPUs and computer clusters.</p>

<p>Thunder is largely inspired by <a href="http://torch.ch">Torch 7</a>, Facebook's <a href="http://github.com/facebook/thpp">TH++</a>, and <a href="http://eblearn.sourceforge.net">EBLearn</a>'s <a href="http://eblearn.sourceforge.net/libidx.html">libidx</a>. In fact, the name "Thunder" came from "TH--" if "under" could be interpreted as "--".</p>

<p>The library just had its development began. Contribution is very welcomed! Please contact Xiang Zhang (xiang.zhang [at] nyu.edu) for details.</p>

<h2>
<a id="downloads" class="anchor" href="#downloads" aria-hidden="true"><span class="octicon octicon-link"></span></a>Downloads</h2>

<p><a href="https://github.com/thunder-nyc/Thunder/releases">Current release</a> of Thunder is version 0.2.0. You can download it from our <a href="https://github.com/thunder-nyc/Thunder/releases">release page</a> or check it out in our <a href="https://github.com/thunder-nyc/Thunder/tree/v0.2.0">Github repository</a>.</p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h2>

<p>Here is a list of prerequisites you need to have to make sure Thunder compiles</p>

<ul>
<li>A compiler that supports C++11. Some examples are <a href="https://gcc.gnu.org">gcc</a> &gt;= 4.8 and <a href="http://clang.llvm.org">llvm/clang</a> &gt;= 3.4.</li>
</ul>

<h3>
<a id="compile-thunder" class="anchor" href="#compile-thunder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compile Thunder</h3>

<p>Thunder can be installed via cmake. To configure the project, please execute</p>

<div class="highlight highlight-sh"><pre>$ cmake</pre></div>

<p>Then, you can compile Thunder by</p>

<div class="highlight highlight-sh"><pre>$ make</pre></div>

<p>If you want to install the project, you can use the following command after cmake configuration.</p>

<div class="highlight highlight-sh"><pre>$ make install</pre></div>

<p>To set the installation prefix, you can add an option like <code>-DCMAKE_INSTALL_PREFIX=/usr/local</code> to the cmake command.</p>

<p>Under Apple OS X you might get a warning regarding <a href="http://www.cmake.org/cmake/help/v3.0/policy/CMP0042.html">CMP0042</a>. Since it is safe to ignore the warning, you can add an option <code>-Wno-dev</code> to supress it.</p>

<h3>
<a id="compile-tests" class="anchor" href="#compile-tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compile Tests</h3>

<p>To compile tests, you can add an option <code>-DBUILD_THUNDER_TESTS=ON</code> to the cmake command. Then, you can run the tests by</p>

<div class="highlight highlight-sh"><pre>$ make <span class="pl-c1">test</span></pre></div>

<p>In most systems the tests should be finished with no problems. However, it is possible that you may encounter occasional numerical precision errors depending on your compiler and standard C++ library. Checking the CTest logs manually is needed to make sure everything is okay.</p>

<h2>
<a id="features" class="anchor" href="#features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Features</h2>

<p>Thunder has many exciting features. The following is a preview list. Some of them are already in the current public source code.</p>

<h3>
<a id="device-transparency" class="anchor" href="#device-transparency" aria-hidden="true"><span class="octicon octicon-link"></span></a>Device Transparency</h3>

<p>Device transparency means that we can transfer data between tensors living on different hardware seamlessly. For example</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a tensor of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">cpu_tensor</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Create a tensor living on NVIDIA GPU and copy from CPU tensor.</span>
<span class="pl-c">// Only explicit static cast is needed.</span>
FloatCudaTensor gpu_tensor = <span class="pl-k">static_cast</span>&lt; FloatCudaTensor &gt;(cpu_tensor);</pre></div>

<h3>
<a id="reference-semantics" class="anchor" href="#reference-semantics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reference Semantics</h3>

<p>Tensors in Thunder do not manage memory; rather, they contain <a href="http://en.cppreference.com/w/cpp/memory/shared_ptr">thread-safe C++11 shared pointers</a> to underlying <code>Storage</code> objects. Unless explicitly created by constructors, static tensor creators or a call to <code>Tensor::clone()</code> for deep copying, Thunder tensors are light-weight objects that can be copied, moved or returned without heavy side effects.</p>

<p>That being said, we still have static memory deallocation when a <code>Storage</code> is not linked by anybody. This provides us with both fast Tensor operations and tight memory control without requiring any explicit memory calls by the user.</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Using tensor constructors create new underlying Storage object.</span>
DoubleTensor <span class="pl-en">tensor</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Static tensor creators also create new underlying Storage objects.</span>
DoubleTensor created_tensor = DoubleTensor::ones(tensor.size());

<span class="pl-c">// Copy constructor still points to the same Storage object.</span>
DoubleTensor copied_tensor = tensor;

<span class="pl-c">// Subtensor operators still points to the same Storage object,</span>
<span class="pl-c">// but now we have a different subtensor view of size 2x8x7x10</span>
DoubleTensor sub_tensor = tensor[{{<span class="pl-c1">1</span>,<span class="pl-c1">2</span>},{<span class="pl-c1">1</span>,<span class="pl-c1">8</span>}}]

<span class="pl-c">// However, the call to 'clone()' creates new underlying Storage.</span>
<span class="pl-c">// It is essentially a 'deep copy'.</span>
DoubleTensor cloned_tensor = tensor.clone();</pre></div>

<h3>
<a id="range-based-for-loop" class="anchor" href="#range-based-for-loop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Range-based <code>for</code> Loop</h3>

<p>We support the new <a href="http://en.cppreference.com/w/cpp/language/range-for">C++11 range-based <code>for</code> loop</a> on tensors. In Thunder, a range-based <code>for</code> loop iterates through the first dimension of the tensor.</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a tensor of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">tensor</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Create a vector of size 10</span>
DoubleTensor <span class="pl-en">vector</span>(<span class="pl-c1">10</span>);

<span class="pl-c">// Create a vector of size 7 storing result data</span>
DoubleTensor result = DoubleTensor::zeros(<span class="pl-c1">7</span>);

<span class="pl-c">// Create a default blas device</span>
DoubleBlas blas_device;

<span class="pl-c">// Create a default random device</span>
DoubleRandom rand_device;

<span class="pl-c">// Each t is of size 9x7x10</span>
<span class="pl-k">for</span> (<span class="pl-k">const</span> DoubleTensor &amp;t : tensor) {
    <span class="pl-c">// Each s is of size 7x10</span>
    <span class="pl-k">for</span> (<span class="pl-k">const</span> DoubleTensor &amp;s : t) {
        <span class="pl-c">// Do matrix-vector multiplication with vector sampled</span>
        <span class="pl-c">// from normal distribution with mean = 0 and std = 1</span>
        result += blas_device.<span class="pl-c1">gemv</span>(s, rand_device.<span class="pl-c1">normal</span>(vector, <span class="pl-c1">0</span>, <span class="pl-c1">1</span>));
    }
}</pre></div>

<h3>
<a id="lambda-expression" class="anchor" href="#lambda-expression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lambda Expression</h3>

<p>In Thunder, each tensor can accept a <a href="http://en.cppreference.com/w/cpp/language/lambda">lambda expression</a> to read or change its values. The following is an example</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a tensor of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">tensor</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Create a value to store the sum</span>
<span class="pl-k">double</span> sum = <span class="pl-c1">0</span>;

<span class="pl-c">// Apply a lambda that sums up the values and assign current sum to current value</span>
tensor.apply(
   [&amp;sum](<span class="pl-k">double</span> v) {
      sum = sum + v;
      <span class="pl-k">return</span> sum;
    });</pre></div>

<h3>
<a id="complex-numbers" class="anchor" href="#complex-numbers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Complex Numbers</h3>

<p>Thunder library support complex numbers natively.</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create 2 tensors of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">tensor1</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);
DoubleTensor <span class="pl-en">tensor2</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Construct a complex tensor using polar</span>
DoubleComplexTensor complex_tensor = DoubleComplexTensor::polar(tensor1, tensor2);

<span class="pl-c">// Get the complex norm of the tensor</span>
DoubleTensor norm_tensor = complex_tensor.getCnrm();</pre></div>

<h3>
<a id="serialization" class="anchor" href="#serialization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Serialization</h3>

<p>Thunder provides its own serialization functionalities that are very extensible. It can</p>

<ul>
<li>Serialize all fundamental types</li>
<li>Avoid duplicated data saving for pointers</li>
<li>Track polymorphic types and do correct serialization</li>
<li>Easily extensible and non-intrusive for classes</li>
</ul>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a tensor of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">tensor</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Create a text serializer that serializes to a string</span>
StringTextSerializer string_serializer;

<span class="pl-c">// Serialize the tensor</span>
string_serializer.save(tensor);

<span class="pl-c">// Now you can see the content of the serialized data</span>
<span class="pl-en">printf</span>(<span class="pl-s"><span class="pl-pds">"</span>Serialized data: <span class="pl-c1">%s</span><span class="pl-cce">\n</span><span class="pl-pds">"</span></span>, string_serializer.protocol().stream().str().c_str());</pre></div>

<h3>
<a id="random-generators" class="anchor" href="#random-generators" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Generators</h3>

<p>We support all <a href="http://en.cppreference.com/w/cpp/numeric/random">random generators provided by the C++11 standard library</a>. They include</p>

<ul>
<li>Discrete uniform distribution</li>
<li>Continuous uniform distribution</li>
<li>Bernoulli distribution</li>
<li>Binomial distribution</li>
<li>Negative binomial distribution</li>
<li>Geometric distribution</li>
<li>Poisson distribution</li>
<li>Exponential distribution</li>
<li>Gamma distribution</li>
<li>Weibull distribution</li>
<li>Extreme value distribution</li>
<li>Normal distribution</li>
<li>Log normal distribution</li>
<li>Chi squared distribution</li>
<li>Cauchy distribution</li>
<li>Fisher F distribution</li>
<li>Student T distribution</li>
</ul>

<p>For example</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a random number generator</span>
DoubleRandom generator;

<span class="pl-c">// Generate a tensor of size 3x9x7x10 from a gamma distribution</span>
<span class="pl-c">// with alpha = 1.0 and beta = 1.0.</span>
DoubleTensor tensor = generator.gamma({<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>}, <span class="pl-c1">1.0</span>, <span class="pl-c1">1.0</span>);</pre></div>

<h3>
<a id="batch-blas" class="anchor" href="#batch-blas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Batch BLAS</h3>

<p>Our BLAS routines support batch mode. The batch mode offers possiblity of speeding up BLAS routines in CPU or GPU without changing the underlying single-core implementation. This design should be more practical and easier to speed up.</p>

<div class="highlight highlight-cpp"><pre><span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">thunder</span><span class="pl-k">;</span>

<span class="pl-c">// Create a BLAS computing device</span>
DoubleBlas blas_device;

<span class="pl-c">// Create a tensor of size 3x9x7x10</span>
DoubleTensor <span class="pl-en">tensor1</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">7</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Create another tensor of size 3x9x10</span>
DoubleTensor <span class="pl-en">tensor2</span>(<span class="pl-c1">3</span>, <span class="pl-c1">9</span>, <span class="pl-c1">10</span>);

<span class="pl-c">// Computing matrix-vector multiplication in batch mode</span>
<span class="pl-c">// Now, 'result' is a tensor of size 3x9x7.</span>
DoubleTensor result = blas_device.gemv(tensor1, tensor2);</pre></div>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-56015701-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>


  </body>
</html>
